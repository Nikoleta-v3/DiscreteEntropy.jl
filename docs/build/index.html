<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Home · DiscreteEntropy.jl</title><script data-outdated-warner src="assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href>DiscreteEntropy.jl</a></span></div><form class="docs-search" action="search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>Home</a><ul class="internal"><li><a class="tocitem" href="#Multiplicities"><span>Multiplicities</span></a></li><li><a class="tocitem" href="#Frequentist-Estimators"><span>Frequentist Estimators</span></a></li><li><a class="tocitem" href="#Bayesian-Estimators"><span>Bayesian Estimators</span></a></li><li><a class="tocitem" href="#Resampling"><span>Resampling</span></a></li><li><a class="tocitem" href="#Divergence"><span>Divergence</span></a></li><li><a class="tocitem" href="#Utilities"><span>Utilities</span></a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Home</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Home</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/kellino/DiscreteEntropy.jl/blob/main/docs/src/index.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="DiscreteEntropy"><a class="docs-heading-anchor" href="#DiscreteEntropy">DiscreteEntropy</a><a id="DiscreteEntropy-1"></a><a class="docs-heading-anchor-permalink" href="#DiscreteEntropy" title="Permalink"></a></h1><p>A <a href="http://julialang.org">Julia</a> package for the estimation of Shannon entropy of discrete distributions.</p><h2 id="Multiplicities"><a class="docs-heading-anchor" href="#Multiplicities">Multiplicities</a><a id="Multiplicities-1"></a><a class="docs-heading-anchor-permalink" href="#Multiplicities" title="Permalink"></a></h2><p>DiscreteEntropy uses the multiplicities representation of data. Given a histogram of samples</p><h2 id="Frequentist-Estimators"><a class="docs-heading-anchor" href="#Frequentist-Estimators">Frequentist Estimators</a><a id="Frequentist-Estimators-1"></a><a class="docs-heading-anchor-permalink" href="#Frequentist-Estimators" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="DiscreteEntropy.maximum_likelihood" href="#DiscreteEntropy.maximum_likelihood"><code>DiscreteEntropy.maximum_likelihood</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">maximum_likelihood(data::CountData)::Float64</code></pre><p>Returns the maximum likelihood estimation of Shannon entropy.</p><p class="math-container">\[\hat{H}_{ML} = \log(n) - \frac{1}{n} \sum_{k=1}^{K}h_k \log(h_k)\]</p><p>where n is the number of samples</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kellino/DiscreteEntropy.jl/blob/f52a19094fda598efd9479db1704d11c4a442101/src/Frequentist/frequentist.jl#L6-L15">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="DiscreteEntropy.jackknife_ml" href="#DiscreteEntropy.jackknife_ml"><code>DiscreteEntropy.jackknife_ml</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">jackknife_ml(data::CountData; corrected=false)::Tuple{Float64, Float64}</code></pre><p>Returns the <em>jackknifed</em> estimate of data and the variance of the jackknifing (not the variance of the estimator itself).</p><p>If corrected in true, then the variance is scaled with n-1, else it is scaled with n</p><p>As found in the <a href="https://academic.oup.com/biomet/article/65/3/625/234287">paper</a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kellino/DiscreteEntropy.jl/blob/f52a19094fda598efd9479db1704d11c4a442101/src/Frequentist/frequentist.jl#L26-L34">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="DiscreteEntropy.miller_madow" href="#DiscreteEntropy.miller_madow"><code>DiscreteEntropy.miller_madow</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">miller_madow(data::CountData)::Float64</code></pre><p>Returns the maximum likelihood estimation of Shannon entropy, with a positive offset based on the total number of samples seen (n) and the support size (K).</p><p class="math-container">\[\hat{H}_{MM} = \hat{H}_{ML} + \frac{K - 1}{2n}\]</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kellino/DiscreteEntropy.jl/blob/f52a19094fda598efd9479db1704d11c4a442101/src/Frequentist/frequentist.jl#L39-L48">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="DiscreteEntropy.grassberger" href="#DiscreteEntropy.grassberger"><code>DiscreteEntropy.grassberger</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">grassberger(data::CountData)::Float64</code></pre><p>Returns the Grassberger estimation of Shannon entropy.</p><p class="math-container">\[\hat{H}_G = log(n) - \frac{1}{n} \sum_{k=1}^{K} h_k \; G(h_k)\]</p><p>This is essentially the same as <span>$\hat{H}_{ML}$</span>, but with the logarithm swapped for the scalar function <span>$G$</span></p><p>where</p><p class="math-container">\[G(h) = \psi(h) + \frac{1}{2}(-1)^h \big( \psi(\frac{h+1}{2} - \psi(\frac{h}{2}))\]</p><p>This is the solution to <span>$G(h) = \psi(h) + (-1)^h \int_0^1 \frac{x^h - 1}{x+1} dx$</span> as given in the <a href="https://arxiv.org/pdf/physics/0307138v2.pdf">paper</a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kellino/DiscreteEntropy.jl/blob/f52a19094fda598efd9479db1704d11c4a442101/src/Frequentist/frequentist.jl#L58-L76">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="DiscreteEntropy.schurmann" href="#DiscreteEntropy.schurmann"><code>DiscreteEntropy.schurmann</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">schurmann(data::CountData, ξ::Float64 = ℯ^(-1/2))::Float64</code></pre><p><a href="https://arxiv.org/pdf/cond-mat/0403192.pdf">schurmann</a></p><p class="math-container">\[\hat{H}_{SHU} = \psi(n) - \frac{1}{n} \sum_{k=1}^{K} \, y_x \big( \psi(y_x) + (-1)^{y_x} ∫_0^{\frac{1}{\xi} - 1} \frac{t^{y_x}-1}{1+t}dt \big)
\]</p><p>This is no one ideal value for <span>$\xi$</span>, however the paper suggests <span>$e^{(-1/2)} \approx 0.6$</span></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kellino/DiscreteEntropy.jl/blob/f52a19094fda598efd9479db1704d11c4a442101/src/Frequentist/frequentist.jl#L88-L99">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="DiscreteEntropy.schurmann_generalised" href="#DiscreteEntropy.schurmann_generalised"><code>DiscreteEntropy.schurmann_generalised</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">schurmann_generalised(data::CountData, xis::Vector{Float64})::Float64</code></pre><p><a href="https://arxiv.org/pdf/2111.11175.pdf">schurmann_generalised</a></p><p class="math-container">\[\hat{H}_{SHU} = \psi(n) - \frac{1}{n} \sum_{k=1}^{K} \, y_x \big( \psi(y_x) + (-1)^{y_x} ∫_0^{\frac{1}{\xi_x} - 1} \frac{t^{y_x}-1}{1+t}dt \big)
\]</p><p>Accepts a vector is <span>$ξ$</span> values, rather than just one.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kellino/DiscreteEntropy.jl/blob/f52a19094fda598efd9479db1704d11c4a442101/src/Frequentist/frequentist.jl#L108-L119">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="DiscreteEntropy.zhang" href="#DiscreteEntropy.zhang"><code>DiscreteEntropy.zhang</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">zhang(data::CountData)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kellino/DiscreteEntropy.jl/blob/f52a19094fda598efd9479db1704d11c4a442101/src/Frequentist/frequentist.jl#L162-L164">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="DiscreteEntropy.chao_shen" href="#DiscreteEntropy.chao_shen"><code>DiscreteEntropy.chao_shen</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">chao_shen(data::CountData)

wip</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kellino/DiscreteEntropy.jl/blob/f52a19094fda598efd9479db1704d11c4a442101/src/Frequentist/frequentist.jl#L129-L133">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="DiscreteEntropy.bonachela" href="#DiscreteEntropy.bonachela"><code>DiscreteEntropy.bonachela</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">bonachela(data::CountData)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kellino/DiscreteEntropy.jl/blob/f52a19094fda598efd9479db1704d11c4a442101/src/Frequentist/frequentist.jl#L170-L172">source</a></section></article><h2 id="Bayesian-Estimators"><a class="docs-heading-anchor" href="#Bayesian-Estimators">Bayesian Estimators</a><a id="Bayesian-Estimators-1"></a><a class="docs-heading-anchor-permalink" href="#Bayesian-Estimators" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="DiscreteEntropy.bayes" href="#DiscreteEntropy.bayes"><code>DiscreteEntropy.bayes</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">bayes(α::Float64, data::CountData)::Float64</code></pre><p>Returns an estimate of Shannon entropy given data and a concentration parameter <span>$α$</span>.</p><p class="math-container">\[\hat{H}_{\text{Bayes}} = - \sum_{k=1}^{K} \hat{p}_k^{\text{Bayes}} \; \log \hat{p}_k^{\text{Bayes}}\]</p><p>where</p><p class="math-container">\[p_k^{\text{Bayes}} = \frac{k + α}{n + A}\]</p><p>and</p><p class="math-container">\[A = \sum_{x=1}^{K} α_{x}\]</p><p>In addition to setting your own α, we have the following suggested choices</p><ol><li><a href="https://ieeexplore.ieee.org/document/1056331">jeffrey</a> : α = 0.5</li><li>laplace: α = 1.0</li><li>schurmann_grassberger: α = 1 / K</li><li>minimax: α = √{n} / K</li></ol></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kellino/DiscreteEntropy.jl/blob/f52a19094fda598efd9479db1704d11c4a442101/src/Bayesian/bayesian.jl#L4-L30">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="DiscreteEntropy.nsb" href="#DiscreteEntropy.nsb"><code>DiscreteEntropy.nsb</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">nsb(data; k=data.K)</code></pre><p>Returns the Bayesian estimate of Shannon entropy of data, using the Nemenman, Shafee, Bialek algorithm</p><p class="math-container">\[\hat{H}^{\text{NSB}} = \frac{ \int_0^{\ln(K)} d\xi \, \rho(\xi, \textbf{n}) \langle H^m \rangle_{\beta (\xi)}  }
                            { \int_0^{\ln(K)} d\xi \, \rho(\xi\mid n)}\]</p><p>where</p><p class="math-container">\[\rho(\xi \mid \textbf{n}) =
    \mathcal{P}(\beta (\xi)) \frac{ \Gamma(\kappa(\xi))}{\Gamma(N + \kappa(\xi))}
    \prod_{i=1}^K \frac{\Gamma(n_i + \beta(\xi))}{\Gamma(\beta(\xi))}\]</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kellino/DiscreteEntropy.jl/blob/f52a19094fda598efd9479db1704d11c4a442101/src/Bayesian/nsb.jl#L108-L125">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="DiscreteEntropy.ansb" href="#DiscreteEntropy.ansb"><code>DiscreteEntropy.ansb</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">ansb(data::CountData; undersampled::Float64=0.1)::Float64</code></pre><p class="math-container">\[\hat{H}_{ANSB} = \frac{C_\gamma}{\ln(2)} - 1 + 2 \ln(N) - \psi_0(\Delta)\]</p><p>where <span>$C_\gamma$</span> is Euler&#39;s Gamma Constant <span>$\approx 0.57721...$</span>, <span>$\psi_0$</span> is the digamma function and <span>$\Delta$</span> the number of coincidences in the data.</p><p>Returns the <a href="https://arxiv.org/pdf/physics/0306063.pdf">Asymptotic NSB estimator</a> (equations 11 and 12)</p><p>This is designed for the extremely undersampled regime (K ~ N) and diverges with N when well-sampled. ANSB requires that <span>$N/K → 0$</span>, which we set to be <span>$N/K &lt; 0.1$</span> by default</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kellino/DiscreteEntropy.jl/blob/f52a19094fda598efd9479db1704d11c4a442101/src/Bayesian/nsb.jl#L8-L22">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="DiscreteEntropy.pym" href="#DiscreteEntropy.pym"><code>DiscreteEntropy.pym</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">pym(mm::Vector{Int64}, icts::Vector{Int64})::Float64</code></pre><p>A more or less faithful port of the original <a href="https://github.com/pillowlab/PYMentropy">matlab code</a> to Julia</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kellino/DiscreteEntropy.jl/blob/f52a19094fda598efd9479db1704d11c4a442101/src/Bayesian/pym.jl#L129-L135">source</a></section></article><h2 id="Resampling"><a class="docs-heading-anchor" href="#Resampling">Resampling</a><a id="Resampling-1"></a><a class="docs-heading-anchor-permalink" href="#Resampling" title="Permalink"></a></h2><p>We can also resample data</p><article class="docstring"><header><a class="docstring-binding" id="DiscreteEntropy.jackknife" href="#DiscreteEntropy.jackknife"><code>DiscreteEntropy.jackknife</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">jackknife(data::CountData, statistic::Function; corrected=false)</code></pre><p>Returns the jacknifed estimate of <em>statistic</em> on data.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kellino/DiscreteEntropy.jl/blob/f52a19094fda598efd9479db1704d11c4a442101/src/resample.jl#L16-L20">source</a></section></article><h2 id="Divergence"><a class="docs-heading-anchor" href="#Divergence">Divergence</a><a id="Divergence-1"></a><a class="docs-heading-anchor-permalink" href="#Divergence" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="DiscreteEntropy.kl_divergence" href="#DiscreteEntropy.kl_divergence"><code>DiscreteEntropy.kl_divergence</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">kl_divergence(p::AbstractVector, q::AbstractVector)::Float64</code></pre><p class="math-container">\[D_{KL}(P ‖ Q) = \sum_{x \in X} P(x) \log \left( \frac{P(x)}{Q(x)} \right)\]</p><p>Returns the <a href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence#Interpretations">Kullback-Lebler Divergence</a> between two discrete distributions. Both distributions needs to be defined over the same space, so length(p) == length(q). If the distributions are not normalised, they will be.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kellino/DiscreteEntropy.jl/blob/f52a19094fda598efd9479db1704d11c4a442101/src/divergence.jl#L1-L11">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="DiscreteEntropy.jeffreys_divergence" href="#DiscreteEntropy.jeffreys_divergence"><code>DiscreteEntropy.jeffreys_divergence</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">jeffreys_divergence(p, q)
(link)[https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7516653/]</code></pre><p class="math-container">\[J(p, q) = D_{KL}(p \Vert q) + D_{KL}(q \Vert p)\]</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kellino/DiscreteEntropy.jl/blob/f52a19094fda598efd9479db1704d11c4a442101/src/divergence.jl#L55-L62">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="DiscreteEntropy.jensen_shannon_divergence" href="#DiscreteEntropy.jensen_shannon_divergence"><code>DiscreteEntropy.jensen_shannon_divergence</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">jenson_shannon_divergence(p::AbstractVector, q::AbstractVector)::Float64</code></pre><p>Returns the Jenson Shannon Divergence between discrete distributions <span>$p$</span> and <span>$q$</span>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kellino/DiscreteEntropy.jl/blob/f52a19094fda598efd9479db1704d11c4a442101/src/divergence.jl#L23-L27">source</a></section><section><div><p class="math-container">\[\widehat{JS}(p, q) = \hat{H}\left(\frac{p + q}{2} \right) - \left( \frac{H(p) + H(q)}{2} \right)
\]</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kellino/DiscreteEntropy.jl/blob/f52a19094fda598efd9479db1704d11c4a442101/src/divergence.jl#L36-L42">source</a></section></article><h2 id="Utilities"><a class="docs-heading-anchor" href="#Utilities">Utilities</a><a id="Utilities-1"></a><a class="docs-heading-anchor-permalink" href="#Utilities" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="DiscreteEntropy.logx" href="#DiscreteEntropy.logx"><code>DiscreteEntropy.logx</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">logx(x)::Float64</code></pre><p>Returns natural logarithm of x, or 0.0 if x is zero</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kellino/DiscreteEntropy.jl/blob/f52a19094fda598efd9479db1704d11c4a442101/src/utils.jl#L3-L6">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="DiscreteEntropy.xlogx" href="#DiscreteEntropy.xlogx"><code>DiscreteEntropy.xlogx</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">xlogx(x::Float64)</code></pre><p>Returns <code>x * log(x)</code> for <code>x ≥ 0</code>, or 0.0 if x is zero</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kellino/DiscreteEntropy.jl/blob/f52a19094fda598efd9479db1704d11c4a442101/src/utils.jl#L14-L17">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="DiscreteEntropy.to_bits" href="#DiscreteEntropy.to_bits"><code>DiscreteEntropy.to_bits</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">to_bits(x::Float64)</code></pre><p>Return <span>$\frac{h}{\log(2)}$</span> where h is in nats</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kellino/DiscreteEntropy.jl/blob/f52a19094fda598efd9479db1704d11c4a442101/src/utils.jl#L22-L25">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="DiscreteEntropy.to_bans" href="#DiscreteEntropy.to_bans"><code>DiscreteEntropy.to_bans</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">to_bans(x::Float64)</code></pre><p>Return <span>$\frac{h}{log(10)}$</span> where <code>h</code> is in nats</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kellino/DiscreteEntropy.jl/blob/f52a19094fda598efd9479db1704d11c4a442101/src/utils.jl#L30-L33">source</a></section></article></article><nav class="docs-footer"><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.24 on <span class="colophon-date" title="Tuesday 21 February 2023 16:20">Tuesday 21 February 2023</span>. Using Julia version 1.8.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
