var documenterSearchIndex = {"docs":
[{"location":"#DiscreteEntropy","page":"Home","title":"DiscreteEntropy","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"A Julia package for the estimation of Shannon entropy of discrete distributions.","category":"page"},{"location":"#Multiplicities","page":"Home","title":"Multiplicities","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"DiscreteEntropy uses the multiplicities representation of data. Given a histogram of samples","category":"page"},{"location":"#Frequentist-Estimators","page":"Home","title":"Frequentist Estimators","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"maximum_likelihood\nmiller_madow\ngrassberger\nschurmann\nzhang\nchao_shen\nbonachela","category":"page"},{"location":"#DiscreteEntropy.maximum_likelihood","page":"Home","title":"DiscreteEntropy.maximum_likelihood","text":"maximum_likelihood(data::CountData)::Float64\n\nReturns the maximum likelihood estimation of Shannon entropy.\n\nhatH_ML = log(n) - frac1n sum_k=1^Kh_k log(h_k)\n\nwhere n is the number of samples\n\n\n\n\n\n","category":"function"},{"location":"#DiscreteEntropy.miller_madow","page":"Home","title":"DiscreteEntropy.miller_madow","text":"miller_madow(data::CountData)::Float64\n\nReturns the maximum likelihood estimation of Shannon entropy, with a positive offset based on the total number of samples seen (n) and the support size (K).\n\nhatH_MM = hatH_ML + fracK - 12n\n\n\n\n\n\n","category":"function"},{"location":"#DiscreteEntropy.grassberger","page":"Home","title":"DiscreteEntropy.grassberger","text":"grassberger(data::CountData)::Float64\n\nReturns the Grassberger estimation of Shannon entropy.\n\nhatH_G = log(n) - frac1n sum_k=1^K h_k  G(h_k)\n\nThis is essentially the same as hatH_ML, but with the logarithm swapped for the scalar function G\n\nwhere\n\nG(h) = psi(h) + frac12(-1)^h big( psi(frach+12 - psi(frach2))\n\nThis is the solution to G(h) = psi(h) + (-1)^h int_0^1 fracx^h - 1x+1 dx as given in the paper\n\n\n\n\n\n","category":"function"},{"location":"#DiscreteEntropy.schurmann","page":"Home","title":"DiscreteEntropy.schurmann","text":"schurmann(data::CountData, ξ::Float64 = ℯ^(-1/2))::Float64\n\nschurmann\n\nhatH_SHU = psi(n) - frac1n sum_k=1^K  h_k big( psi(h_k) + (-1)^h_k _0^1ζ - 1 fract^h_k-11+tdt big)\n\n\nThis is no one ideal value for zeta, however the paper suggests e^(-12) approx 06\n\n\n\n\n\n","category":"function"},{"location":"#DiscreteEntropy.zhang","page":"Home","title":"DiscreteEntropy.zhang","text":"zhang(data::CountData)\n\n\n\n\n\n","category":"function"},{"location":"#DiscreteEntropy.bonachela","page":"Home","title":"DiscreteEntropy.bonachela","text":"bonachela(data::CountData)\n\n\n\n\n\n","category":"function"},{"location":"#Bayesian-Estimators","page":"Home","title":"Bayesian Estimators","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"bayes\nnsb","category":"page"},{"location":"#DiscreteEntropy.bayes","page":"Home","title":"DiscreteEntropy.bayes","text":"bayes(α::Float64, data::CountData)::Float64\n\nReturns an estimate of Shannon entropy given data and a concentration parameter α.\n\nhatH_textBayes = - sum_k=1^K hatp_k^textBayes  log hatp_k^textBayes\n\nwhere\n\np_k^textBayes = frack + αn + A\n\nand\n\nA = sum_x=1^K α_x\n\nIn addition to setting your own α, we have the following suggested choices\n\njeffrey : α = 0.5\nlaplace: α = 1.0\nschurmann_grassberger: α = 1 / K\nminimax: α = √{n} / K\n\n\n\n\n\n","category":"function"},{"location":"#DiscreteEntropy.nsb","page":"Home","title":"DiscreteEntropy.nsb","text":"nsb(k, data::CountData)\nnsb(data::CountData)\nnsb(samples::AbstractVector)\n\nBayesian estimator\n\n\n\n\n\n","category":"function"},{"location":"#Utilities","page":"Home","title":"Utilities","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"xlogx\nto_bits\nto_bans","category":"page"},{"location":"#DiscreteEntropy.xlogx","page":"Home","title":"DiscreteEntropy.xlogx","text":"xlogx(x::Float64)\n\nReturn x * log(x) for x ≥ 0, handling x == 0 by return 0.\n\n\n\n\n\n","category":"function"},{"location":"#DiscreteEntropy.to_bits","page":"Home","title":"DiscreteEntropy.to_bits","text":"to_bits(x::Float64)\n\nReturn frachlog(2) where h is in nats\n\n\n\n\n\n","category":"function"},{"location":"#DiscreteEntropy.to_bans","page":"Home","title":"DiscreteEntropy.to_bans","text":"to_bans(x::Float64)\n\nReturn frachlog(10) where h is in nats\n\n\n\n\n\n","category":"function"}]
}
